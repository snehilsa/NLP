{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import nltk\n",
    "import logging\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow and tensorflow_hub before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use these data\n",
    "data=pd.read_csv('outfit_combinations.csv')\n",
    "d3=pd.read_csv('Full+data.csv')\n",
    "d3=d3.dropna(axis=1,how='all')\n",
    "data=data.merge(d3[['product_id','description']],on='product_id',how='inner')\n",
    "data=data.dropna()\n",
    "data=data.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter your input \n",
      "'shoe:(01DMBRYVA2ZFDYRYY5TRQZJTBE)'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_type</th>\n",
       "      <th>recommended_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DMBRYVA2P5H24WK0HTK4R0A1</td>\n",
       "      <td>bottom</td>\n",
       "      <td>slim knit skirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DMBRYVA2PEPWFTT7RMP5AA1T</td>\n",
       "      <td>top</td>\n",
       "      <td>rib mock neck tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DMBRYVA2S5T9W793F4CY41HE</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>medium margaux leather satchel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DMBRYVA2ZFDYRYY5TRQZJTBD</td>\n",
       "      <td>shoe</td>\n",
       "      <td>penelope mid cap toe pump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id outfit_type                recommended_item\n",
       "0  01DMBRYVA2P5H24WK0HTK4R0A1      bottom                 slim knit skirt\n",
       "0  01DMBRYVA2PEPWFTT7RMP5AA1T         top              rib mock neck tank\n",
       "0  01DMBRYVA2S5T9W793F4CY41HE  accessory1  medium margaux leather satchel\n",
       "0  01DMBRYVA2ZFDYRYY5TRQZJTBD        shoe       penelope mid cap toe pump"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell after running the function cell and enter inputs either as product ID or Descriptions\n",
    "#to get recommendations\n",
    "#If you enter Product Id and it isn't found in our system, you'll see the closest product id\n",
    "#You can enter either the query in format A or B (product id/description)\n",
    "query=input(\"Please Enter your input \\n\")\n",
    "recommend_USE(data,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data - columns outfit_item_type,brand,product_full_name\n",
    "def recommend_USE(data,query):\n",
    "    from nltk.corpus import stopwords\n",
    "    columns=['outfit_item_type','brand','product_full_name','description']\n",
    "    for j in columns:\n",
    "        for i in range(0,len(data)):\n",
    "            new=re.sub('[^a-zA-Z0-9]', ' ',str(data.loc[i,j]))\n",
    "            p=[]\n",
    "            for k in new.split():\n",
    "                separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "                new = separated.lower()\n",
    "                p.append(new)\n",
    "            ls=WordNetLemmatizer()\n",
    "            new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "            new = ' '.join(new)\n",
    "            data.loc[i,j]=new\n",
    "    data['all_info']=data['product_id']+' '+data['brand']+' '+data['outfit_item_type']+' '+data['product_full_name']+\" \"+data['description']\n",
    "    #Universal Sentence encoder Vectorize four columns\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_hub as hub\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "    V1 = embed(data['all_info'])\n",
    "    #Preprocess data - columns outfit_item_type,brand,product_full_name\n",
    "    new=re.sub('[^0-9a-zA-Z]', ' ',str(query))\n",
    "    p=[]\n",
    "    for k in new.split():\n",
    "        separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "        new = separated.lower()\n",
    "        p.append(new)\n",
    "    ls=WordNetLemmatizer()\n",
    "    new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "    new = ' '.join(new)\n",
    "    query=new\n",
    "\n",
    "    #Universal Sentence Vectorize Query\n",
    "    Q = embed([query])\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    #Find similarity with all documents\n",
    "    results=cosine_similarity(V1,Q)\n",
    "    \n",
    "    import heapq\n",
    "    k=list(data.iloc[heapq.nlargest(1,range(len(results)),results.__getitem__),0])\n",
    "    for i in k:\n",
    "        f=pd.DataFrame()\n",
    "        for j in range(0,len(data)):\n",
    "            l=[]\n",
    "            if data.loc[j,'outfit_id']==i:\n",
    "                l.append(list(data.iloc[j,[1,2,4]].values))\n",
    "                if l!=[]:\n",
    "                    f=f.append(l)\n",
    "        f.columns=['product_id','outfit_type','recommended_item']\n",
    "        f['product_id']=f['product_id'].str.upper()\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
