{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import logging\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('outfit_combinations.csv')\n",
    "d3=pd.read_csv('Full+data.csv')\n",
    "d3=d3.dropna(axis=1,how='all')\n",
    "data=data.merge(d3[['product_id','description']],on='product_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()\n",
    "data=data.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bottom', 'top', 'accessory1', 'shoe', 'onepiece', 'accessory2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['outfit_item_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c3bb50cdd75c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             self.obj._data = self.obj._data.setitem(indexer=indexer,\n\u001b[0;32m--> 656\u001b[0;31m                                                     value=value)\n\u001b[0m\u001b[1;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'setitem'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;31m# coerce and try to infer the dtypes of the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_try_coerce_and_cast_result\u001b[0;34m(self, result, dtype)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_coerce_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_cast_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_try_cast_result\u001b[0;34m(self, result, dtype)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_datetime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mis_bool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2631\u001b[0m                                           placement=placement)\n\u001b[1;32m   2632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2633\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m         \"\"\" we can be a bool if we have only bool values but are of type\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Preprocess data - columns outfit_item_type,brand,product_full_name,product_id\n",
    "nltk.download('stopwords')\n",
    "columns=['outfit_item_type','brand','product_full_name','product_id','description']\n",
    "for j in columns:\n",
    "    corpus = []\n",
    "    for i in range(0,len(data)):\n",
    "        new=re.sub('[^0-9a-zA-Z]', ' ',str(data.loc[i,j]))\n",
    "        p=[]\n",
    "        for k in new.split():\n",
    "            separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "            new = separated.lower()\n",
    "            p.append(new)\n",
    "        ls=WordNetLemmatizer()\n",
    "        new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "        new = ' '.join(new)\n",
    "        data.loc[i,j]=new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outfit_id            0\n",
       "product_id           0\n",
       "outfit_item_type     0\n",
       "brand                0\n",
       "product_full_name    0\n",
       "description          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining info from all four columns into one before vectorization\n",
    "data['all_info']=data['product_id']+' '+data['brand']+' '+data['outfit_item_type']+' '+data['product_full_name']+\" \"+data['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outfit_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_item_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>all_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01dmbryva2p5h24wk0htk4r0a1</td>\n",
       "      <td>bottom</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>slim knit skirt</td>\n",
       "      <td>nice skirt</td>\n",
       "      <td>01dmbryva2p5h24wk0htk4r0a1 eileen fisher botto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DMHCX50CFX5YNG99F3Y65GQW</td>\n",
       "      <td>01dmbryva2p5h24wk0htk4r0a1</td>\n",
       "      <td>bottom</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>slim knit skirt</td>\n",
       "      <td>nice skirt</td>\n",
       "      <td>01dmbryva2p5h24wk0htk4r0a1 eileen fisher botto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01dmbryva2pepwftt7rmp5aa1t</td>\n",
       "      <td>top</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>rib mock neck tank</td>\n",
       "      <td>nice tank</td>\n",
       "      <td>01dmbryva2pepwftt7rmp5aa1t eileen fisher top r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DMHCX50CFX5YNG99F3Y65GQW</td>\n",
       "      <td>01dmbryva2pepwftt7rmp5aa1t</td>\n",
       "      <td>top</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>rib mock neck tank</td>\n",
       "      <td>nice tank</td>\n",
       "      <td>01dmbryva2pepwftt7rmp5aa1t eileen fisher top r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01dmbryva2s5t9w793f4cy41he</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>kate spade new york</td>\n",
       "      <td>medium margaux leather satchel</td>\n",
       "      <td>nice bag</td>\n",
       "      <td>01dmbryva2s5t9w793f4cy41he kate spade new york...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    outfit_id                  product_id outfit_item_type  \\\n",
       "0  01DDBHC62ES5K80P0KYJ56AM2T  01dmbryva2p5h24wk0htk4r0a1           bottom   \n",
       "1  01DMHCX50CFX5YNG99F3Y65GQW  01dmbryva2p5h24wk0htk4r0a1           bottom   \n",
       "2  01DDBHC62ES5K80P0KYJ56AM2T  01dmbryva2pepwftt7rmp5aa1t              top   \n",
       "3  01DMHCX50CFX5YNG99F3Y65GQW  01dmbryva2pepwftt7rmp5aa1t              top   \n",
       "4  01DDBHC62ES5K80P0KYJ56AM2T  01dmbryva2s5t9w793f4cy41he       accessory1   \n",
       "\n",
       "                 brand               product_full_name description  \\\n",
       "0        eileen fisher                 slim knit skirt  nice skirt   \n",
       "1        eileen fisher                 slim knit skirt  nice skirt   \n",
       "2        eileen fisher              rib mock neck tank   nice tank   \n",
       "3        eileen fisher              rib mock neck tank   nice tank   \n",
       "4  kate spade new york  medium margaux leather satchel    nice bag   \n",
       "\n",
       "                                            all_info  \n",
       "0  01dmbryva2p5h24wk0htk4r0a1 eileen fisher botto...  \n",
       "1  01dmbryva2p5h24wk0htk4r0a1 eileen fisher botto...  \n",
       "2  01dmbryva2pepwftt7rmp5aa1t eileen fisher top r...  \n",
       "3  01dmbryva2pepwftt7rmp5aa1t eileen fisher top r...  \n",
       "4  01dmbryva2s5t9w793f4cy41he kate spade new york...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - COSINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF Vectorize three columns\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['all_info'])\n",
    "terms = vectorizer.get_feature_names()\n",
    "#c=pd.DataFrame(p.toarray().transpose(),index=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample query\n",
    "query='shoe: Penelope Mid Cap Toe Pump (01DMBRYVA2ZFDYRYY5TRQZJTAD)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Clean query\n",
    "#Preprocess data - columns outfit_item_type,brand,product_full_name\n",
    "nltk.download('stopwords')\n",
    "new=re.sub('[^a-zA-Z0-9]', ' ',str(query))\n",
    "p=[]\n",
    "for k in new.split():\n",
    "    separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "    new = separated.lower()\n",
    "    p.append(new)\n",
    "ls=WordNetLemmatizer()\n",
    "new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "new = ' '.join(new)\n",
    "query=new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shoe penelope mid cap toe pump 01dmbryva2zfdyryy5trqzjtad'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned query\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF Query\n",
    "Q = vectorizer.transform([query])\n",
    "terms = vectorizer.get_feature_names()\n",
    "#Q=pd.DataFrame(p.toarray().transpose(),index=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find similarity with all documents\n",
    "results=cosine_similarity(X,Q).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outfit_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_item_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>all_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01dmbryva2p5h24wk0htk4r0a1</td>\n",
       "      <td>bottom</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>slim knit skirt</td>\n",
       "      <td>nice skirt</td>\n",
       "      <td>01dmbryva2p5h24wk0htk4r0a1 eileen fisher botto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01dmbryva2pepwftt7rmp5aa1t</td>\n",
       "      <td>top</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>rib mock neck tank</td>\n",
       "      <td>nice tank</td>\n",
       "      <td>01dmbryva2pepwftt7rmp5aa1t eileen fisher top r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01dmbryva2s5t9w793f4cy41he</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>kate spade new york</td>\n",
       "      <td>medium margaux leather satchel</td>\n",
       "      <td>nice bag</td>\n",
       "      <td>01dmbryva2s5t9w793f4cy41he kate spade new york...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01dmbryva2zfdyryy5trqzjtbd</td>\n",
       "      <td>shoe</td>\n",
       "      <td>tory burch</td>\n",
       "      <td>penelope mid cap toe pump</td>\n",
       "      <td>nice shoe</td>\n",
       "      <td>01dmbryva2zfdyryy5trqzjtbd tory burch shoe pen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    outfit_id                  product_id outfit_item_type  \\\n",
       "0  01DDBHC62ES5K80P0KYJ56AM2T  01dmbryva2p5h24wk0htk4r0a1           bottom   \n",
       "2  01DDBHC62ES5K80P0KYJ56AM2T  01dmbryva2pepwftt7rmp5aa1t              top   \n",
       "4  01DDBHC62ES5K80P0KYJ56AM2T  01dmbryva2s5t9w793f4cy41he       accessory1   \n",
       "6  01DDBHC62ES5K80P0KYJ56AM2T  01dmbryva2zfdyryy5trqzjtbd             shoe   \n",
       "\n",
       "                 brand               product_full_name description  \\\n",
       "0        eileen fisher                 slim knit skirt  nice skirt   \n",
       "2        eileen fisher              rib mock neck tank   nice tank   \n",
       "4  kate spade new york  medium margaux leather satchel    nice bag   \n",
       "6           tory burch       penelope mid cap toe pump   nice shoe   \n",
       "\n",
       "                                            all_info  \n",
       "0  01dmbryva2p5h24wk0htk4r0a1 eileen fisher botto...  \n",
       "2  01dmbryva2pepwftt7rmp5aa1t eileen fisher top r...  \n",
       "4  01dmbryva2s5t9w793f4cy41he kate spade new york...  \n",
       "6  01dmbryva2zfdyryy5trqzjtbd tory burch shoe pen...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recommended outfit based upon row which had maximum cosine similiarity\n",
    "data[data['outfit_id']==data.iloc[np.argmax(results),0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find max of an array full of cosine similarity numbers\n",
    "import heapq\n",
    "k=list(data.iloc[heapq.nlargest(1,range(len(results)),results.__getitem__),0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe for recommendations\n",
    "f=pd.DataFrame()\n",
    "for i in k:\n",
    "    for j in range(0,len(data)):\n",
    "        l=[]\n",
    "        if data.loc[j,'outfit_id']==i:\n",
    "            l.append(list(data.iloc[j,[1,2,3,4]].values))\n",
    "            if l!=[]:\n",
    "                f=f.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.columns=['product_id','outfit_type','brand','product_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01dmbryva2p5h24wk0htk4r0a1</td>\n",
       "      <td>bottom</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>slim knit skirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01dmbryva2pepwftt7rmp5aa1t</td>\n",
       "      <td>top</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>rib mock neck tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01dmbryva2s5t9w793f4cy41he</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>kate spade new york</td>\n",
       "      <td>medium margaux leather satchel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01dmbryva2zfdyryy5trqzjtbd</td>\n",
       "      <td>shoe</td>\n",
       "      <td>tory burch</td>\n",
       "      <td>penelope mid cap toe pump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id outfit_type                brand  \\\n",
       "0  01dmbryva2p5h24wk0htk4r0a1      bottom        eileen fisher   \n",
       "0  01dmbryva2pepwftt7rmp5aa1t         top        eileen fisher   \n",
       "0  01dmbryva2s5t9w793f4cy41he  accessory1  kate spade new york   \n",
       "0  01dmbryva2zfdyryy5trqzjtbd        shoe           tory burch   \n",
       "\n",
       "                     product_info  \n",
       "0                 slim knit skirt  \n",
       "0              rib mock neck tank  \n",
       "0  medium margaux leather satchel  \n",
       "0       penelope mid cap toe pump  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f #Table of recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2 VecCosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(data['all_info'])]\n",
    "model = Doc2Vec(documents, vector_size=50, window=20, min_count=1, workers=3,negative=10,alpha=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outfit_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_item_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>all_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4338</th>\n",
       "      <td>01DVVBRQ7M32WCCAD47WRTEFFZ</td>\n",
       "      <td>01drzjxqx38z9zy07tw52b39b2</td>\n",
       "      <td>shoe</td>\n",
       "      <td>rag bone</td>\n",
       "      <td>fei mule</td>\n",
       "      <td>almond toed mule contrasting wooden stacked he...</td>\n",
       "      <td>01drzjxqx38z9zy07tw52b39b2 rag bone shoe fei m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>01DVVBRQ7M32WCCAD47WRTEFFZ</td>\n",
       "      <td>01dt0dm6nx4zfpgp2zcadmkvqw</td>\n",
       "      <td>accessory2</td>\n",
       "      <td>theory</td>\n",
       "      <td>double faced overlay coat</td>\n",
       "      <td>minimal overcoat luxe wool cashmere exudes ref...</td>\n",
       "      <td>01dt0dm6nx4zfpgp2zcadmkvqw theory accessory2 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>01DVVBRQ7M32WCCAD47WRTEFFZ</td>\n",
       "      <td>01dt50xz89mhr0atrcpjgbnr3e</td>\n",
       "      <td>top</td>\n",
       "      <td>la ligne</td>\n",
       "      <td>striped cashmere sweater</td>\n",
       "      <td>beige ivory cashmere slip 100 cashmere hand wa...</td>\n",
       "      <td>01dt50xz89mhr0atrcpjgbnr3e la ligne top stripe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>01DVVBRQ7M32WCCAD47WRTEFFZ</td>\n",
       "      <td>01dt516tgq4efywxgkv2er5wra</td>\n",
       "      <td>bottom</td>\n",
       "      <td>j brand</td>\n",
       "      <td>joan cropped cotton blend corduroy wide leg pant</td>\n",
       "      <td>black cotton blend corduroy button concealed z...</td>\n",
       "      <td>01dt516tgq4efywxgkv2er5wra j brand bottom joan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>01DVVBRQ7M32WCCAD47WRTEFFZ</td>\n",
       "      <td>01dvvbr6208whc8qx2e2cv411m</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>prada</td>\n",
       "      <td>belle small leather shoulder bag</td>\n",
       "      <td>white leather calf tab fastening front flap co...</td>\n",
       "      <td>01dvvbr6208whc8qx2e2cv411m prada accessory1 be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       outfit_id                  product_id outfit_item_type  \\\n",
       "4338  01DVVBRQ7M32WCCAD47WRTEFFZ  01drzjxqx38z9zy07tw52b39b2             shoe   \n",
       "4347  01DVVBRQ7M32WCCAD47WRTEFFZ  01dt0dm6nx4zfpgp2zcadmkvqw       accessory2   \n",
       "4365  01DVVBRQ7M32WCCAD47WRTEFFZ  01dt50xz89mhr0atrcpjgbnr3e              top   \n",
       "4371  01DVVBRQ7M32WCCAD47WRTEFFZ  01dt516tgq4efywxgkv2er5wra           bottom   \n",
       "4383  01DVVBRQ7M32WCCAD47WRTEFFZ  01dvvbr6208whc8qx2e2cv411m       accessory1   \n",
       "\n",
       "         brand                                 product_full_name  \\\n",
       "4338  rag bone                                          fei mule   \n",
       "4347    theory                         double faced overlay coat   \n",
       "4365  la ligne                          striped cashmere sweater   \n",
       "4371   j brand  joan cropped cotton blend corduroy wide leg pant   \n",
       "4383     prada                  belle small leather shoulder bag   \n",
       "\n",
       "                                            description  \\\n",
       "4338  almond toed mule contrasting wooden stacked he...   \n",
       "4347  minimal overcoat luxe wool cashmere exudes ref...   \n",
       "4365  beige ivory cashmere slip 100 cashmere hand wa...   \n",
       "4371  black cotton blend corduroy button concealed z...   \n",
       "4383  white leather calf tab fastening front flap co...   \n",
       "\n",
       "                                               all_info  \n",
       "4338  01drzjxqx38z9zy07tw52b39b2 rag bone shoe fei m...  \n",
       "4347  01dt0dm6nx4zfpgp2zcadmkvqw theory accessory2 d...  \n",
       "4365  01dt50xz89mhr0atrcpjgbnr3e la ligne top stripe...  \n",
       "4371  01dt516tgq4efywxgkv2er5wra j brand bottom joan...  \n",
       "4383  01dvvbr6208whc8qx2e2cv411m prada accessory1 be...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2=model.infer_vector([query]).reshape((1,-1))\n",
    "a=0\n",
    "for i in range(0,len(data)):\n",
    "    v1=model.infer_vector([data.loc[i,'all_info']]).reshape((1,-1))\n",
    "    if cosine_similarity(v1,v2)>a:\n",
    "        a=cosine_similarity(v1, v2)\n",
    "        p=i\n",
    "data[data['outfit_id']==data.iloc[p,0]]\n",
    "#p has the index of maximum similairity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"slim fitting, straight leg pant with a center back zipper and slightly cropped leg and slightly cropped leg- BRAND: Reformation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Clean query\n",
    "#Preprocess data - columns outfit_item_type,brand,product_full_name\n",
    "nltk.download('stopwords')\n",
    "new=re.sub('[^a-zA-Z]', ' ',str(query))\n",
    "p=[]\n",
    "for k in new.split():\n",
    "    separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "    new = separated.lower()\n",
    "    p.append(new)\n",
    "ls=WordNetLemmatizer()\n",
    "new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "new = ' '.join(new)\n",
    "query=new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'slim fitting straight leg pant center back zipper slightly cropped leg slightly cropped leg brand reformation'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_item_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>01dpehs0xh9pdd1gh5ze4p43a2</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>sole society</td>\n",
       "      <td>cassi belt bag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>01dpkmh0d252jkmaa27mfct5gm</td>\n",
       "      <td>bottom</td>\n",
       "      <td>reformation</td>\n",
       "      <td>marlon pant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>01dpkn20q3j0be3cs896dqb6er</td>\n",
       "      <td>top</td>\n",
       "      <td>reformation</td>\n",
       "      <td>jane sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>01dpknhqdg6gptkv97cfqrjdhe</td>\n",
       "      <td>shoe</td>\n",
       "      <td>reformation</td>\n",
       "      <td>giulia satin heel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    product_id outfit_item_type         brand  \\\n",
       "35  01dpehs0xh9pdd1gh5ze4p43a2       accessory1  sole society   \n",
       "37  01dpkmh0d252jkmaa27mfct5gm           bottom   reformation   \n",
       "38  01dpkn20q3j0be3cs896dqb6er              top   reformation   \n",
       "39  01dpknhqdg6gptkv97cfqrjdhe             shoe   reformation   \n",
       "\n",
       "    product_full_name  \n",
       "35     cassi belt bag  \n",
       "37        marlon pant  \n",
       "38       jane sweater  \n",
       "39  giulia satin heel  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dataframe using row that had maximum similarity\n",
    "b=0\n",
    "for i in range(0,len(data)):\n",
    "    a=fuzz.partial_ratio(data.loc[i,'all_info'],query)\n",
    "    if a>b:\n",
    "        b=a\n",
    "        p=i\n",
    "f=data[data['outfit_id']==data.iloc[p,0]]\n",
    "pd.DataFrame(f[['product_id','outfit_item_type','brand','product_full_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Preprocess data - columns outfit_item_type,brand,product_full_name\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "def recommend_items(data,query):\n",
    "    columns=['outfit_item_type','brand','product_full_name','description']\n",
    "    for j in columns:\n",
    "        for i in range(0,len(data)):\n",
    "            new=re.sub('[^a-zA-Z0-9]', ' ',str(data.loc[i,j]))\n",
    "            p=[]\n",
    "            for k in new.split():\n",
    "                separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "                new = separated.lower()\n",
    "                p.append(new)\n",
    "            ls=WordNetLemmatizer()\n",
    "            new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "            new = ' '.join(new)\n",
    "            data.loc[i,j]=new\n",
    "    data['all_info']=data['product_id']+' '+data['brand']+' '+data['outfit_item_type']+' '+data['product_full_name']+\" \"+data['description']\n",
    "        #TFIDF Vectorize three columns\n",
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(data['all_info'])\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    #c=pd.DataFrame(p.toarray().transpose(),index=terms)\n",
    "    #Clean query\n",
    "    #Preprocess data - columns outfit_item_type,brand,product_full_name\n",
    "    nltk.download('stopwords')\n",
    "    new=re.sub('[^0-9a-zA-Z]', ' ',str(query))\n",
    "    p=[]\n",
    "    for k in new.split():\n",
    "        separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "        new = separated.lower()\n",
    "        p.append(new)\n",
    "    ls=WordNetLemmatizer()\n",
    "    new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "    new = ' '.join(new)\n",
    "    query=new\n",
    "\n",
    "    #TFIDF Query\n",
    "    Q = vectorizer.transform([query])\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    #Q=pd.DataFrame(p.toarray().transpose(),index=terms)\n",
    "    \n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    #Find similarity with all documents\n",
    "    results=cosine_similarity(X,Q).reshape((-1,1))\n",
    "    \n",
    "    import heapq\n",
    "    k=list(data.iloc[heapq.nlargest(1,range(len(results)),results.__getitem__),0])\n",
    "    for i in k:\n",
    "        f=pd.DataFrame()\n",
    "        for j in range(0,len(data)):\n",
    "            l=[]\n",
    "            if data.loc[j,'outfit_id']==i:\n",
    "                l.append(list(data.iloc[j,[1,2,4]].values))\n",
    "                if l!=[]:\n",
    "                    f=f.append(l)\n",
    "        f.columns=['product_id','brand','item']\n",
    "        f['product_id']=f['product_id'].str.upper()\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPEHS0XH9PDD1GH5ZE4P43A2</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>cassi belt bag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPKMH0D252JKMAA27MFCT5GM</td>\n",
       "      <td>bottom</td>\n",
       "      <td>marlon pant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPKN20Q3J0BE3CS896DQB6ER</td>\n",
       "      <td>top</td>\n",
       "      <td>jane sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPKNHQDG6GPTKV97CFQRJDHE</td>\n",
       "      <td>shoe</td>\n",
       "      <td>giulia satin heel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id       brand               item\n",
       "0  01DPEHS0XH9PDD1GH5ZE4P43A2  accessory1     cassi belt bag\n",
       "0  01DPKMH0D252JKMAA27MFCT5GM      bottom        marlon pant\n",
       "0  01DPKN20Q3J0BE3CS896DQB6ER         top       jane sweater\n",
       "0  01DPKNHQDG6GPTKV97CFQRJDHE        shoe  giulia satin heel"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_items(data,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='bottom: DESCRIPTION: slim fitting, straight leg pant with a center back zipper and slightly cropped leg – BRAND: Reformation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query='Sexy silky, a-line mini skirt zipper Benson skirt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_fuzz(data,query):\n",
    "    from fuzzywuzzy import fuzz\n",
    "    from fuzzywuzzy import process\n",
    "    from nltk.corpus import stopwords\n",
    "    nltk.download('stopwords')\n",
    "    columns=['outfit_item_type','brand','product_full_name','description']\n",
    "    for j in columns:\n",
    "        for i in range(0,len(data)):\n",
    "            new=re.sub('[^a-zA-Z0-9]', ' ',str(data.loc[i,j]))\n",
    "            p=[]\n",
    "            for k in new.split():\n",
    "                separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "                new = separated.lower()\n",
    "                p.append(new)\n",
    "            ls=WordNetLemmatizer()\n",
    "            new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "            new = ' '.join(new)\n",
    "            data.loc[i,j]=new\n",
    "    data['all_info']=data['product_id']+' '+data['brand']+' '+data['outfit_item_type']+' '+data['product_full_name']+' '+data['description']\n",
    "        #TFIDF Vectorize three columns\n",
    "    #Clean query\n",
    "    #Preprocess data - columns outfit_item_type,brand,product_full_name\n",
    "    \n",
    "    new=re.sub('[^a-zA-Z]', ' ',str(query))\n",
    "    p=[]\n",
    "    for k in new.split():\n",
    "        separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "        new = separated.lower()\n",
    "        p.append(new)\n",
    "    ls=WordNetLemmatizer()\n",
    "    new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "    new = ' '.join(new)\n",
    "    query=new\n",
    "    b=0\n",
    "    for i in range(0,len(data)):\n",
    "        a=fuzz.partial_ratio(data.loc[i,'all_info'],query)\n",
    "        if a>b:\n",
    "            b=a\n",
    "            p=i\n",
    "    CD=data[data['outfit_id']==data.iloc[p,0]]\n",
    "    CD['product_id']=CD['product_id'].str.upper()\n",
    "    \n",
    "    return CD.iloc[:,[1,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_item_type</th>\n",
       "      <th>product_full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>01DPEHS0XH9PDD1GH5ZE4P43A2</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>cassi belt bag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>01DPKMH0D252JKMAA27MFCT5GM</td>\n",
       "      <td>bottom</td>\n",
       "      <td>marlon pant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>01DPKN20Q3J0BE3CS896DQB6ER</td>\n",
       "      <td>top</td>\n",
       "      <td>jane sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>01DPKNHQDG6GPTKV97CFQRJDHE</td>\n",
       "      <td>shoe</td>\n",
       "      <td>giulia satin heel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    product_id outfit_item_type  product_full_name\n",
       "35  01DPEHS0XH9PDD1GH5ZE4P43A2       accessory1     cassi belt bag\n",
       "37  01DPKMH0D252JKMAA27MFCT5GM           bottom        marlon pant\n",
       "38  01DPKN20Q3J0BE3CS896DQB6ER              top       jane sweater\n",
       "39  01DPKNHQDG6GPTKV97CFQRJDHE             shoe  giulia satin heel"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_fuz(data,query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "V1 = embed(data['all_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = embed([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=cosine_similarity(V1,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "k=list(data.iloc[heapq.nlargest(2,range(len(results)),results.__getitem__),0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            0           1                  2\n",
      "0  01DPEHS0XH9PDD1GH5ZE4P43A2  accessory1     Cassi Belt Bag\n",
      "0  01DPKMH0D252JKMAA27MFCT5GM      bottom        Marlon Pant\n",
      "0  01DPKN20Q3J0BE3CS896DQB6ER         top       Jane Sweater\n",
      "0  01DPKNHQDG6GPTKV97CFQRJDHE        shoe  Giulia Satin Heel\n",
      "                            0           1  \\\n",
      "0  01DPEHS0XH9PDD1GH5ZE4P43A2  accessory1   \n",
      "0  01DPKMH0D252JKMAA27MFCT5GM      bottom   \n",
      "0  01DPKN20Q3J0BE3CS896DQB6ER         top   \n",
      "0  01DPKNHQDG6GPTKV97CFQRJDHE        shoe   \n",
      "0  01DT0C8FVZJ77EEMXPSKD0VG3A      bottom   \n",
      "0  01DT0DHR8X5GZYR1KVBWAT3END  accessory2   \n",
      "0  01DT0DM2ZFCWSBKZ19W8WGPBQN  accessory1   \n",
      "0  01DT51234VHAHGPTR89SZJ50V0        shoe   \n",
      "0  01DVP9VHNTNDG4BX0SSHSTCZG8         top   \n",
      "\n",
      "                                                   2  \n",
      "0                                     Cassi Belt Bag  \n",
      "0                                        Marlon Pant  \n",
      "0                                       Jane Sweater  \n",
      "0                                  Giulia Satin Heel  \n",
      "0                         Anson Crepe Slim Fit Pants  \n",
      "0             Madison Single-Breasted Leather Jacket  \n",
      "0  Small Monogram Matelassé Metallic Leather Wall...  \n",
      "0  Andrea 85 zebra-print calf hair and leather mules  \n",
      "0                        Athena lace-up crepe blouse  \n"
     ]
    }
   ],
   "source": [
    "f=pd.DataFrame()\n",
    "for i in k:\n",
    "    for j in range(0,len(data)):\n",
    "        l=[]\n",
    "        if data.loc[j,'outfit_id']==i:\n",
    "            l.append(list(data.iloc[j,[1,2,4]].values))\n",
    "            if l!=[]:\n",
    "                f=f.append(l)\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01DQ8ME3M3QS9MQGZCQHXDHE1R', '01DVPABBBDK2JJ2JGSKXNKZ13M']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPEHS0XH9PDD1GH5ZE4P43A2</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>Cassi Belt Bag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPKMH0D252JKMAA27MFCT5GM</td>\n",
       "      <td>bottom</td>\n",
       "      <td>Marlon Pant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPKN20Q3J0BE3CS896DQB6ER</td>\n",
       "      <td>top</td>\n",
       "      <td>Jane Sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPKNHQDG6GPTKV97CFQRJDHE</td>\n",
       "      <td>shoe</td>\n",
       "      <td>Giulia Satin Heel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DT0C8FVZJ77EEMXPSKD0VG3A</td>\n",
       "      <td>bottom</td>\n",
       "      <td>Anson Crepe Slim Fit Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DT0DHR8X5GZYR1KVBWAT3END</td>\n",
       "      <td>accessory2</td>\n",
       "      <td>Madison Single-Breasted Leather Jacket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DT0DM2ZFCWSBKZ19W8WGPBQN</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>Small Monogram Matelassé Metallic Leather Wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DT51234VHAHGPTR89SZJ50V0</td>\n",
       "      <td>shoe</td>\n",
       "      <td>Andrea 85 zebra-print calf hair and leather mules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DVP9VHNTNDG4BX0SSHSTCZG8</td>\n",
       "      <td>top</td>\n",
       "      <td>Athena lace-up crepe blouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0           1  \\\n",
       "0  01DPEHS0XH9PDD1GH5ZE4P43A2  accessory1   \n",
       "0  01DPKMH0D252JKMAA27MFCT5GM      bottom   \n",
       "0  01DPKN20Q3J0BE3CS896DQB6ER         top   \n",
       "0  01DPKNHQDG6GPTKV97CFQRJDHE        shoe   \n",
       "0  01DT0C8FVZJ77EEMXPSKD0VG3A      bottom   \n",
       "0  01DT0DHR8X5GZYR1KVBWAT3END  accessory2   \n",
       "0  01DT0DM2ZFCWSBKZ19W8WGPBQN  accessory1   \n",
       "0  01DT51234VHAHGPTR89SZJ50V0        shoe   \n",
       "0  01DVP9VHNTNDG4BX0SSHSTCZG8         top   \n",
       "\n",
       "                                                   2  \n",
       "0                                     Cassi Belt Bag  \n",
       "0                                        Marlon Pant  \n",
       "0                                       Jane Sweater  \n",
       "0                                  Giulia Satin Heel  \n",
       "0                         Anson Crepe Slim Fit Pants  \n",
       "0             Madison Single-Breasted Leather Jacket  \n",
       "0  Small Monogram Matelassé Metallic Leather Wall...  \n",
       "0  Andrea 85 zebra-print calf hair and leather mules  \n",
       "0                        Athena lace-up crepe blouse  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Universal Sentence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data - columns outfit_item_type,brand,product_full_name\n",
    "def recommend_USE(data,query):\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "    columns=['outfit_item_type','brand','product_full_name','description']\n",
    "    for j in columns:\n",
    "        for i in range(0,len(data)):\n",
    "            new=re.sub('[^a-zA-Z0-9]', ' ',str(data.loc[i,j]))\n",
    "            p=[]\n",
    "            for k in new.split():\n",
    "                separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "                new = separated.lower()\n",
    "                p.append(new)\n",
    "            ls=WordNetLemmatizer()\n",
    "            new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "            new = ' '.join(new)\n",
    "            data.loc[i,j]=new\n",
    "    data['all_info']=data['product_id']+' '+data['brand']+' '+data['outfit_item_type']+' '+data['product_full_name']+\" \"+data['description']\n",
    "    #Universal Sentence encoder Vectorize four columns\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_hub as hub\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "    V1 = embed(data['all_info'])\n",
    "    #Preprocess data - columns outfit_item_type,brand,product_full_name\n",
    "    nltk.download('stopwords')\n",
    "    new=re.sub('[^0-9a-zA-Z]', ' ',str(query))\n",
    "    p=[]\n",
    "    for k in new.split():\n",
    "        separated=re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ',k)\n",
    "        new = separated.lower()\n",
    "        p.append(new)\n",
    "    ls=WordNetLemmatizer()\n",
    "    new = [ls.lemmatize(word) for word in p if not word in set(stopwords.words('english'))]\n",
    "    new = ' '.join(new)\n",
    "    query=new\n",
    "\n",
    "    #Universal Sentence Vectorize Query\n",
    "    Q = embed([query])\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    #Find similarity with all documents\n",
    "    results=cosine_similarity(V1,Q)\n",
    "    \n",
    "    import heapq\n",
    "    k=list(data.iloc[heapq.nlargest(2,range(len(results)),results.__getitem__),0])\n",
    "    for i in k:\n",
    "        f=pd.DataFrame()\n",
    "        for j in range(0,len(data)):\n",
    "            l=[]\n",
    "            if data.loc[j,'outfit_id']==i:\n",
    "                l.append(list(data.iloc[j,[1,2,4]].values))\n",
    "                if l!=[]:\n",
    "                    f=f.append(l)\n",
    "        f.columns=['product_id','brand','item','desc']\n",
    "        f['product_id']=f['product_id'].str.upper()\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "recommend_USE(data,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='01DTJBR06HEYC2WWGJX1RKBZA5 shoe meta boot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>item</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DT2D39AP6T64ZA88WEPQ1C3K</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>miranda croc effect leather shoulder bag</td>\n",
       "      <td>bag brand far launched handbag business enormous success megahit footwear miranda style crafted trend mini silhouette croc effect leather nutella hue front flap open moderately sized interior fit cell beauty essential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DT51AFKN7GGVG7EFW0ZGF3PE</td>\n",
       "      <td>accessory2</td>\n",
       "      <td>ribbed knit wrap cardigan</td>\n",
       "      <td>brown ribbed knit tie front 40 wool 40 acrylic 20 nylon dry clean imported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DT8ND4QVV25CDSARCDFCWZ11</td>\n",
       "      <td>bottom</td>\n",
       "      <td>alloisa belted striped crepe slim leg pant</td>\n",
       "      <td>equipment incorporates sleek tailoring fall 19 lineup label alloisa pant cut lightweight crepe patterned classic pinstripe tapered slim leg shape coordinating belt emphasizes high rise waist style tucked blouse structured blazer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DTJBEY26533CKXMXH26MN2SH</td>\n",
       "      <td>top</td>\n",
       "      <td>metallic wool blend turtleneck</td>\n",
       "      <td>brunello cucinelli short sleeved turtleneck spun blend mohair virgin wool cashmere metallic element shimmer lightweight feel semi sheer body make versatile enough wear throughout year styled different way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DTJBR06HEYC2WWGJX1RKBZA4</td>\n",
       "      <td>shoe</td>\n",
       "      <td>meta snakeskin embossed leather ankle boot</td>\n",
       "      <td>sleek point toe ankle boot crafted supple leather luxe snakeskin embossed finish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id       brand  \\\n",
       "0  01DT2D39AP6T64ZA88WEPQ1C3K  accessory1   \n",
       "0  01DT51AFKN7GGVG7EFW0ZGF3PE  accessory2   \n",
       "0  01DT8ND4QVV25CDSARCDFCWZ11  bottom       \n",
       "0  01DTJBEY26533CKXMXH26MN2SH  top          \n",
       "0  01DTJBR06HEYC2WWGJX1RKBZA4  shoe         \n",
       "\n",
       "                                         item  \\\n",
       "0  miranda croc effect leather shoulder bag     \n",
       "0  ribbed knit wrap cardigan                    \n",
       "0  alloisa belted striped crepe slim leg pant   \n",
       "0  metallic wool blend turtleneck               \n",
       "0  meta snakeskin embossed leather ankle boot   \n",
       "\n",
       "                                                                                                                                                                                                                                   desc  \n",
       "0  bag brand far launched handbag business enormous success megahit footwear miranda style crafted trend mini silhouette croc effect leather nutella hue front flap open moderately sized interior fit cell beauty essential             \n",
       "0  brown ribbed knit tie front 40 wool 40 acrylic 20 nylon dry clean imported                                                                                                                                                            \n",
       "0  equipment incorporates sleek tailoring fall 19 lineup label alloisa pant cut lightweight crepe patterned classic pinstripe tapered slim leg shape coordinating belt emphasizes high rise waist style tucked blouse structured blazer  \n",
       "0  brunello cucinelli short sleeved turtleneck spun blend mohair virgin wool cashmere metallic element shimmer lightweight feel semi sheer body make versatile enough wear throughout year styled different way                          \n",
       "0  sleek point toe ankle boot crafted supple leather luxe snakeskin embossed finish                                                                                                                                                      "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "recommend_USE(data,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehilsaraswat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_item_type</th>\n",
       "      <th>product_full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>01DT2D39AP6T64ZA88WEPQ1C3K</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>miranda croc effect leather shoulder bag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>01DT51AFKN7GGVG7EFW0ZGF3PE</td>\n",
       "      <td>accessory2</td>\n",
       "      <td>ribbed knit wrap cardigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>01DT8ND4QVV25CDSARCDFCWZ11</td>\n",
       "      <td>bottom</td>\n",
       "      <td>alloisa belted striped crepe slim leg pant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>01DTJBEY26533CKXMXH26MN2SH</td>\n",
       "      <td>top</td>\n",
       "      <td>metallic wool blend turtleneck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>01DTJBR06HEYC2WWGJX1RKBZA4</td>\n",
       "      <td>shoe</td>\n",
       "      <td>meta snakeskin embossed leather ankle boot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     product_id outfit_item_type  \\\n",
       "697  01DT2D39AP6T64ZA88WEPQ1C3K  accessory1        \n",
       "716  01DT51AFKN7GGVG7EFW0ZGF3PE  accessory2        \n",
       "753  01DT8ND4QVV25CDSARCDFCWZ11  bottom            \n",
       "760  01DTJBEY26533CKXMXH26MN2SH  top               \n",
       "773  01DTJBR06HEYC2WWGJX1RKBZA4  shoe              \n",
       "\n",
       "                              product_full_name  \n",
       "697  miranda croc effect leather shoulder bag    \n",
       "716  ribbed knit wrap cardigan                   \n",
       "753  alloisa belted striped crepe slim leg pant  \n",
       "760  metallic wool blend turtleneck              \n",
       "773  meta snakeskin embossed leather ankle boot  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_fuzz(data,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
